{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "0a9a1c6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sqlparse in c:\\users\\elam2\\appdata\\roaming\\python\\python311\\site-packages (0.5.1)\n",
      "Requirement already satisfied: sqlglot in c:\\users\\elam2\\appdata\\roaming\\python\\python311\\site-packages (25.14.0)\n",
      "Collecting sqlglot\n",
      "  Obtaining dependency information for sqlglot from https://files.pythonhosted.org/packages/6c/6e/ee658ca20ea29804ea7bc226df2381bbb95dac6a3735fb6218d1657e4d43/sqlglot-25.15.0-py3-none-any.whl.metadata\n",
      "  Downloading sqlglot-25.15.0-py3-none-any.whl.metadata (19 kB)\n",
      "Downloading sqlglot-25.15.0-py3-none-any.whl (400 kB)\n",
      "   ---------------------------------------- 0.0/400.5 kB ? eta -:--:--\n",
      "   ----------- ---------------------------- 112.6/400.5 kB 2.2 MB/s eta 0:00:01\n",
      "   ---------------- ----------------------- 163.8/400.5 kB 2.4 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 317.4/400.5 kB 2.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 400.5/400.5 kB 2.3 MB/s eta 0:00:00\n",
      "Installing collected packages: sqlglot\n",
      "  Attempting uninstall: sqlglot\n",
      "    Found existing installation: sqlglot 25.14.0\n",
      "    Uninstalling sqlglot-25.14.0:\n",
      "      Successfully uninstalled sqlglot-25.14.0\n",
      "Successfully installed sqlglot-25.15.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "!pip install sqlparse --user --upgrade\n",
    "!pip install sqlglot --user --upgrade\n",
    "\n",
    "import sqlglot\n",
    "import sqlglot.expressions as exp\n",
    "from sqlglot import parse_one\n",
    "from sqlglot.optimizer import optimize\n",
    "from sqlglot import optimizer\n",
    "from sqlglot.errors import OptimizeError\n",
    "from sqlglot import lineage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "8c6e9f29",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('stored procedure/sp_otp_shipment_level.txt', 'r') as f:\n",
    "    #remove illegal words\n",
    "    text = f.read().replace('~', '!=')\n",
    "    lines = text.split(';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "d69077ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_2_b_processed = []\n",
    "fail_2_processed = []\n",
    "stored_procedure_called = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "f3b91cf3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for sql in lines:\n",
    "    \n",
    "    if ('insert' in sql.lower() or 'update' in sql.lower()): #grab all building block to build the database\n",
    "        \n",
    "        sql_2_b_processed.append(sql)\n",
    "        \n",
    "    elif ('call' in sql.lower()): #to grap all procedure called within procedure\n",
    "        \n",
    "        stored_procedure_called.append(sql)\n",
    "        \n",
    "    else: \n",
    "    \n",
    "        fail_2_processed.append(sql)\n",
    "        \n",
    "len(sql_2_b_processed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "ab838d48",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Format argument unsupported for TO_CHAR/TO_VARCHAR function\n"
     ]
    }
   ],
   "source": [
    "#prepocessing\n",
    "#change update and insert to respective select statement\n",
    "#addtionally if it is insert: prepare list of output table columns\n",
    "\n",
    "sql = sql_2_b_processed[0]\n",
    "\n",
    "token = ''\n",
    "\n",
    "if('insert' in sql.lower()):\n",
    "    \n",
    "    token = 'insert'\n",
    "    \n",
    "    for expression in sqlglot.parse(sql):\n",
    "        insert_table_name = str(expression.args['this'].this)\n",
    "        columns = []\n",
    "        for column in expression.args['this'].expressions:\n",
    "            columns.append(column.this)\n",
    "        expression_ = str(expression.expression)\n",
    "    \n",
    "    #recompose the list of column into a single string: REAL Columns for the datamart\n",
    "    insert_columns = ', '.join(columns)[:-2]\n",
    "    \n",
    "    sql = expression_\n",
    "    #print(sql)\n",
    "    \n",
    "elif('update' in sql.lower()):\n",
    "    \n",
    "    token = 'update'\n",
    "    \n",
    "    for expression in sqlglot.parse(sql):\n",
    "        #print(expression.args)\n",
    "        table_name = str(expression.args['this'])\n",
    "        field_value_name = expression.expressions\n",
    "    \n",
    "        fieldname = []\n",
    "        value = []\n",
    "    \n",
    "        for pair in field_value_name:\n",
    "            fieldname.append(str(pair.this))\n",
    "            value.append(str(pair.expression))\n",
    "        \n",
    "        from_ = str(expression.args['from'])\n",
    "        where = str(expression.args['where'])\n",
    "\n",
    "        sql_ = ''\n",
    "    \n",
    "        for value_, fieldname_ in zip(value, fieldname):\n",
    "    \n",
    "            sql_ = sql_ + ' ' + value_ + ' AS ' + fieldname_ + ','\n",
    "    \n",
    "        sql_ = sql_[:-1]\n",
    "\n",
    "        sql_ = 'SELECT ' + sql_ + ' FROM ' + table_name + ' JOIN ' + from_.replace('FROM', ' ') + ' ON (' + where.replace('WHERE', ' ') + ')' \n",
    "        sql = sql_\n",
    "    \n",
    "        update_column = fieldname\n",
    "        all_column = update_column\n",
    "\n",
    "else:\n",
    "    print('no action.')\n",
    "    \n",
    "#print(sql)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "41eca45f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#helper functions\n",
    "#find all alias from cte and related table and schema\n",
    "def obtain_table_alias_type(sql):\n",
    "    \n",
    "    for alias in parse_one(sql, dialect=\"redshift\").find_all(exp.TableAlias):\n",
    "        \n",
    "        print(f\"alias => {alias.this.this} | alias_table_type => {type(alias.parent_select)}\" )\n",
    "        \n",
    "        break\n",
    "        \n",
    "#find schema by name\n",
    "def find_schema_by_table_name(table_name):\n",
    "    \n",
    "    for table in parse_one(sql, dialect=\"redshift\").find_all(exp.Table):\n",
    "        \n",
    "        if (table_name == table.name):\n",
    "            return str(table.args['db'])\n",
    "            \n",
    "def obtain_list_column_table(sql):\n",
    "    \n",
    "    column_l = []\n",
    "    table_l = []\n",
    "    alias_l = []\n",
    "    \n",
    "    for column in parse_one(sql, dialect=\"redshift\").find_all(exp.Column):\n",
    "        \n",
    "        column_l.append(column.name)\n",
    "        table_l.append(column.table)\n",
    "        #print(column.key)\n",
    "        #print(f\"Column => {column.name} | DB => {column.table}\" )\n",
    "\n",
    "    return column_l, table_l\n",
    "\n",
    "#find all alias from cte and related table and schema\n",
    "def obtain_list_table_alias(sql):\n",
    "    \n",
    "    unalias_name = []\n",
    "    alias_l = []\n",
    "    related_table_l = []\n",
    "    alias_type_ = []\n",
    "    schema_l = []\n",
    "    \n",
    "    for alias in parse_one(sql, dialect=\"redshift\").find_all(exp.TableAlias):\n",
    "        \n",
    "        table_t = []\n",
    "        #if it is cte\n",
    "        if (alias.parent.name == ''):\n",
    "            alias_type_.append(type(alias.parent.args['this']))\n",
    "            alias_l.append(alias.this.this)\n",
    "            column_t, table_t = obtain_list_column_table(str(alias.parent))\n",
    "            related_table_l.append(list(dict.fromkeys(table_t)))\n",
    "            unalias_name.append(alias.parent.name)\n",
    "            \n",
    "            schema = []\n",
    "            \n",
    "            for table in list(dict.fromkeys(table_t)):\n",
    "                \n",
    "                schema.append(find_schema_by_table_name(table))\n",
    "                \n",
    "            schema_l.append(schema)\n",
    "            \n",
    "        #if it is normal table\n",
    "        else:\n",
    "            alias_type_.append('')\n",
    "            related_table_l.append('')\n",
    "            alias_l.append(alias.this.this)\n",
    "            unalias_name.append(alias.parent.name)\n",
    "            \n",
    "            schema_l.append(find_schema_by_table_name(alias.parent.name))\n",
    "        \n",
    "        #print(f\"Column => {alias_l} | DB => {related_table_l}\" )\n",
    "        \n",
    "    return alias_l, related_table_l, alias_type_, unalias_name, schema_l\n",
    "\n",
    "def find_column_originated(sql):\n",
    "\n",
    "    column_l = []\n",
    "    table_l = []\n",
    "    originated_l = []\n",
    "    \n",
    "    group_column_l = []\n",
    "    group_table_l = []\n",
    "    group_originated_l = []\n",
    "    #print(sql)\n",
    "    \n",
    "    #need to use parse instead of parse_one\n",
    "    for expression in sqlglot.parse(sql):\n",
    "        #print(expression.args)\n",
    "        \n",
    "        keysList = list(expression.args.keys())\n",
    "        #print(keysList)\n",
    "    \n",
    "        for key in keysList:\n",
    "            if expression.args[key] != None:\n",
    "                \n",
    "                #find all expression/join key\n",
    "                if type(expression.args[key]) is list:\n",
    "                    for objecto in expression.args[key]:\n",
    "                        for column in objecto.find_all(exp.Column):\n",
    "                            #print(f\"Column => {column.name} | type => {key}\" )\n",
    "                            column_l.append(column.name)\n",
    "                            table_l.append(column.table)\n",
    "                            originated_l.append(key)\n",
    "                else:\n",
    "                    #list all group by items\n",
    "                    if key == 'group':\n",
    "                        for groupby_clause in expression.args[key].expressions:\n",
    "                            if (type(groupby_clause)==sqlglot.expressions.Column):\n",
    "                                group_column_l.append(groupby_clause.this)\n",
    "                                group_table_l.append(groupby_clause.table)\n",
    "                            else:\n",
    "                                group_column_l.append(groupby_clause)\n",
    "                                group_table_l.append(None)\n",
    "                            group_originated_l.append('group by')\n",
    "    \n",
    "    #combine into one single dataframe\n",
    "    dict = {'output_column': column_l, 'table': table_l, 'action': originated_l} \n",
    "    df_relationship = pd.DataFrame(dict)\n",
    "    dict = {'output_column': group_column_l, 'table': group_table_l, 'action': group_originated_l}\n",
    "    df_group = pd.DataFrame(dict)\n",
    "    df_relationship = df_relationship.append(df_group)\n",
    "    \n",
    "    return df_relationship\n",
    "\n",
    "#just in case if there is union\n",
    "def deep_find_column_originated(sql, table_name):\n",
    "    \n",
    "    sqlglot_ = parse_one(sql)\n",
    "    if (type(sqlglot_)==sqlglot.expressions.Union):\n",
    "        df_union_1 = find_column_originated(str(sqlglot_.args['this']))\n",
    "        df_union_2 = find_column_originated(str(sqlglot_.args['expression']))\n",
    "        \n",
    "        df_union_1['union'] = ' left union'\n",
    "        df_union_2['union'] = ' right union'\n",
    "        \n",
    "        df_ = pd.concat([df_union_1, df_union_2], ignore_index=True)\n",
    "        \n",
    "    else:\n",
    "        df_ = find_column_originated(sql)\n",
    "        df_['union'] = None\n",
    "        \n",
    "    df_['destined_table'] = table_name\n",
    "    return df_ \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "467402c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ELAM2\\AppData\\Local\\Temp\\ipykernel_32324\\4141691527.py:121: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_relationship = df_relationship.append(df_group)\n",
      "C:\\Users\\ELAM2\\AppData\\Local\\Temp\\ipykernel_32324\\4141691527.py:121: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_relationship = df_relationship.append(df_group)\n",
      "C:\\Users\\ELAM2\\AppData\\Local\\Temp\\ipykernel_32324\\4141691527.py:121: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_relationship = df_relationship.append(df_group)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>output_column</th>\n",
       "      <th>table</th>\n",
       "      <th>action</th>\n",
       "      <th>union</th>\n",
       "      <th>destined_table</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>changeoperation</td>\n",
       "      <td>vendor</td>\n",
       "      <td>joins</td>\n",
       "      <td>None</td>\n",
       "      <td>qma_datamart.otp_shipment_level</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>rda_code</td>\n",
       "      <td>z</td>\n",
       "      <td>joins</td>\n",
       "      <td>None</td>\n",
       "      <td>qma_datamart.otp_shipment_level</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>fty_code</td>\n",
       "      <td>vendor</td>\n",
       "      <td>joins</td>\n",
       "      <td>None</td>\n",
       "      <td>qma_datamart.otp_shipment_level</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>src_sys</td>\n",
       "      <td>z</td>\n",
       "      <td>joins</td>\n",
       "      <td>None</td>\n",
       "      <td>qma_datamart.otp_shipment_level</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>src_sys</td>\n",
       "      <td>vendor</td>\n",
       "      <td>joins</td>\n",
       "      <td>None</td>\n",
       "      <td>qma_datamart.otp_shipment_level</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>487</th>\n",
       "      <td>scale_desc</td>\n",
       "      <td>dim_size_scale</td>\n",
       "      <td>joins</td>\n",
       "      <td>right union</td>\n",
       "      <td>z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>488</th>\n",
       "      <td>size</td>\n",
       "      <td>fact_po_dtl</td>\n",
       "      <td>joins</td>\n",
       "      <td>right union</td>\n",
       "      <td>z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>489</th>\n",
       "      <td>scale_code</td>\n",
       "      <td>dim_size_scale</td>\n",
       "      <td>joins</td>\n",
       "      <td>right union</td>\n",
       "      <td>z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>490</th>\n",
       "      <td>src_sys</td>\n",
       "      <td>fact_po_dtl</td>\n",
       "      <td>joins</td>\n",
       "      <td>right union</td>\n",
       "      <td>z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>491</th>\n",
       "      <td>src_sys</td>\n",
       "      <td>dim_size_scale</td>\n",
       "      <td>joins</td>\n",
       "      <td>right union</td>\n",
       "      <td>z</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>81 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       output_column           table action         union  \\\n",
       "95   changeoperation          vendor  joins          None   \n",
       "96          rda_code               z  joins          None   \n",
       "97          fty_code          vendor  joins          None   \n",
       "98           src_sys               z  joins          None   \n",
       "99           src_sys          vendor  joins          None   \n",
       "..               ...             ...    ...           ...   \n",
       "487       scale_desc  dim_size_scale  joins   right union   \n",
       "488             size     fact_po_dtl  joins   right union   \n",
       "489       scale_code  dim_size_scale  joins   right union   \n",
       "490          src_sys     fact_po_dtl  joins   right union   \n",
       "491          src_sys  dim_size_scale  joins   right union   \n",
       "\n",
       "                      destined_table  \n",
       "95   qma_datamart.otp_shipment_level  \n",
       "96   qma_datamart.otp_shipment_level  \n",
       "97   qma_datamart.otp_shipment_level  \n",
       "98   qma_datamart.otp_shipment_level  \n",
       "99   qma_datamart.otp_shipment_level  \n",
       "..                               ...  \n",
       "487                                z  \n",
       "488                                z  \n",
       "489                                z  \n",
       "490                                z  \n",
       "491                                z  \n",
       "\n",
       "[81 rows x 5 columns]"
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#find the position of the column in the sql, whether it is in select/update/insert or join clause or group by\n",
    "df_relation = deep_find_column_originated(sql, insert_table_name)\n",
    "\n",
    "for subquery in parse_one(sql).find_all(exp.Subquery):\n",
    "    \n",
    "    df_subquery = deep_find_column_originated(str(subquery.args['this']), subquery.alias)\n",
    "    df_relation = pd.concat([df_relation, df_subquery], ignore_index=True)\n",
    "\n",
    "df_relation\n",
    "\n",
    "groupby_df = df_relation.loc[df_relation['action']=='group by']\n",
    "column_df = df_relation.loc[df_relation['action']=='expressions']\n",
    "join_df = df_relation.loc[df_relation['action']=='joins']\n",
    "\n",
    "join_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c1074106",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>output_column</th>\n",
       "      <th>first_level_relationship</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>country_of_origin</td>\n",
       "      <td>extract</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>po_cut</td>\n",
       "      <td>extract</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>style</td>\n",
       "      <td>extract</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>color</td>\n",
       "      <td>extract</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>style_description</td>\n",
       "      <td>extract</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>delivery_mode_shipment_load_type</td>\n",
       "      <td>extract</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>pts_issue_date</td>\n",
       "      <td>calculated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>order_amount_local_currency</td>\n",
       "      <td>calculated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>shipped_amt_local_currency</td>\n",
       "      <td>calculated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>season_cleaned</td>\n",
       "      <td>extract</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>73 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       output_column first_level_relationship\n",
       "0                  country_of_origin                  extract\n",
       "1                             po_cut                  extract\n",
       "2                              style                  extract\n",
       "3                              color                  extract\n",
       "4                  style_description                  extract\n",
       "..                               ...                      ...\n",
       "68  delivery_mode_shipment_load_type                  extract\n",
       "69                    pts_issue_date               calculated\n",
       "70       order_amount_local_currency               calculated\n",
       "71        shipped_amt_local_currency               calculated\n",
       "72                    season_cleaned                  extract\n",
       "\n",
       "[73 rows x 2 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#preprocessing: for Insert\n",
    "#find all output columns, columns, table, and schema\n",
    "#1. find all output columns\n",
    "column_list = []\n",
    "table_list = []\n",
    "alias_list = []\n",
    "is_calculated = []\n",
    "\n",
    "for select in parse_one(sql).find_all(exp.Select):\n",
    "    for projection in select.expressions:\n",
    "        temp = projection['this'].args\n",
    "        if (isinstance(temp['this'], sqlglot.expressions.Alias)):\n",
    "            \n",
    "            if (isinstance(temp['this'].this, sqlglot.expressions.Column)):\n",
    "                #column\n",
    "                column_list.append(temp['this'].this.this.this)\n",
    "                #table\n",
    "                table_list.append(temp['this'].this.table)\n",
    "                #alias\n",
    "                alias_list.append(temp['this'].alias)\n",
    "            else:\n",
    "                column_list.append('')\n",
    "                table_list.append('')\n",
    "                alias_list.append('')\n",
    "            \n",
    "        elif (isinstance(temp['this'], sqlglot.expressions.Column)):\n",
    "            #column\n",
    "            column_list.append(temp['this'].this.this)\n",
    "            #table\n",
    "            table_list.append(temp['this'].table)\n",
    "            alias_list.append('')\n",
    "           \n",
    "        else:\n",
    "            column_list.append('')\n",
    "            table_list.append('')\n",
    "            alias_list.append('')\n",
    "    break\n",
    "\n",
    "# Convert to DataFrame\n",
    "dict = {'output_column': all_column, 'first_level_column': column_list, 'first_level_table': table_list, 'first_level_alias': alias_list} \n",
    "   \n",
    "df = pd.DataFrame(dict)\n",
    "df.loc[df['first_level_column']!='', 'first_level_relationship'] = 'extract'\n",
    "df.loc[df['first_level_column']=='', 'first_level_relationship'] = 'calculated'\n",
    "\n",
    "df[['output_column', 'first_level_relationship']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c099b235",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>output_node</th>\n",
       "      <th>alias</th>\n",
       "      <th>reference node</th>\n",
       "      <th>logic</th>\n",
       "      <th>full source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>vendor_ffc</td>\n",
       "      <td>vendor_ffc</td>\n",
       "      <td></td>\n",
       "      <td>CASE WHEN z.src_sys = 'WD' AND COALESCE(vendor...</td>\n",
       "      <td>SELECT CASE WHEN z.src_sys = 'WD' AND COALESCE...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>27</td>\n",
       "      <td>src_sys</td>\n",
       "      <td>z</td>\n",
       "      <td>fact_po_hdr.src_sys AS src_sys</td>\n",
       "      <td>SELECT fact_po_hdr.src_sys AS src_sys FROM qma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>fact_po_hdr.src_sys</td>\n",
       "      <td>fact_po_hdr</td>\n",
       "      <td></td>\n",
       "      <td>qma.fact_po_hdr AS fact_po_hdr</td>\n",
       "      <td>qma.fact_po_hdr AS fact_po_hdr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>27</td>\n",
       "      <td>src_sys</td>\n",
       "      <td>z</td>\n",
       "      <td>fact_po_hdr.src_sys AS src_sys</td>\n",
       "      <td>SELECT fact_po_hdr.src_sys AS src_sys FROM qma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>fact_po_hdr.src_sys</td>\n",
       "      <td>fact_po_hdr</td>\n",
       "      <td></td>\n",
       "      <td>qma.fact_po_hdr AS fact_po_hdr</td>\n",
       "      <td>qma.fact_po_hdr AS fact_po_hdr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>factory_mapping.vendor_ffc</td>\n",
       "      <td>factory_mapping</td>\n",
       "      <td></td>\n",
       "      <td>qma_datamart.mapping_ngcv12_factory AS factory...</td>\n",
       "      <td>qma_datamart.mapping_ngcv12_factory AS factory...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>vendor.vendor_ffc</td>\n",
       "      <td>vendor</td>\n",
       "      <td></td>\n",
       "      <td>qma.dim_fty_supr AS vendor</td>\n",
       "      <td>qma.dim_fty_supr AS vendor</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  output_node            alias reference node  \\\n",
       "0                  vendor_ffc       vendor_ffc                  \n",
       "1                          27          src_sys              z   \n",
       "2         fact_po_hdr.src_sys      fact_po_hdr                  \n",
       "3                          27          src_sys              z   \n",
       "4         fact_po_hdr.src_sys      fact_po_hdr                  \n",
       "5  factory_mapping.vendor_ffc  factory_mapping                  \n",
       "6           vendor.vendor_ffc           vendor                  \n",
       "\n",
       "                                               logic  \\\n",
       "0  CASE WHEN z.src_sys = 'WD' AND COALESCE(vendor...   \n",
       "1                     fact_po_hdr.src_sys AS src_sys   \n",
       "2                     qma.fact_po_hdr AS fact_po_hdr   \n",
       "3                     fact_po_hdr.src_sys AS src_sys   \n",
       "4                     qma.fact_po_hdr AS fact_po_hdr   \n",
       "5  qma_datamart.mapping_ngcv12_factory AS factory...   \n",
       "6                         qma.dim_fty_supr AS vendor   \n",
       "\n",
       "                                         full source  \n",
       "0  SELECT CASE WHEN z.src_sys = 'WD' AND COALESCE...  \n",
       "1  SELECT fact_po_hdr.src_sys AS src_sys FROM qma...  \n",
       "2                     qma.fact_po_hdr AS fact_po_hdr  \n",
       "3  SELECT fact_po_hdr.src_sys AS src_sys FROM qma...  \n",
       "4                     qma.fact_po_hdr AS fact_po_hdr  \n",
       "5  qma_datamart.mapping_ngcv12_factory AS factory...  \n",
       "6                         qma.dim_fty_supr AS vendor  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "column = 'vendor_ffc'\n",
    "\n",
    "print(len(list(lineage.lineage(column, sql).walk())))\n",
    "\n",
    "source_list = []\n",
    "expression_list = []\n",
    "column_list = []\n",
    "alias_list = []\n",
    "reference_list = []\n",
    "\n",
    "for node in lineage.lineage(column, sql).walk():\n",
    "    \n",
    "    #field name\n",
    "    node_ = str(node.name)\n",
    "    \n",
    "    #print(node_)\n",
    "    source = str(node.source)\n",
    "    alias = str(node.expression.alias)\n",
    "    expression = str(node.expression)\n",
    "    #depth = expression.depth\n",
    "    \n",
    "    #full source\n",
    "    source_list.append(source)\n",
    "    alias_list.append(alias)\n",
    "    expression_list.append(expression)\n",
    "    column_list.append(node_)\n",
    "    reference_list.append(node.reference_node_name)\n",
    "    \n",
    "# Convert to DataFrame\n",
    "dict = {'output_node': column_list, 'alias': alias_list, 'reference node': reference_list, 'logic': expression_list, 'full source': source_list} \n",
    "   \n",
    "df_i = pd.DataFrame(dict)\n",
    "df_i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cdef3a2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>output_column</th>\n",
       "      <th>table</th>\n",
       "      <th>action</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>vendor_ffc</td>\n",
       "      <td>vendor</td>\n",
       "      <td>expressions</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>vendor_ffc</td>\n",
       "      <td>vendor</td>\n",
       "      <td>expressions</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>vendor_grp_name</td>\n",
       "      <td>vendor</td>\n",
       "      <td>expressions</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>vendor_grp_name</td>\n",
       "      <td>vendor</td>\n",
       "      <td>expressions</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>changeoperation</td>\n",
       "      <td>vendor</td>\n",
       "      <td>joins</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>fty_code</td>\n",
       "      <td>vendor</td>\n",
       "      <td>joins</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>src_sys</td>\n",
       "      <td>vendor</td>\n",
       "      <td>joins</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      output_column   table       action\n",
       "25       vendor_ffc  vendor  expressions\n",
       "28       vendor_ffc  vendor  expressions\n",
       "29  vendor_grp_name  vendor  expressions\n",
       "38  vendor_grp_name  vendor  expressions\n",
       "95  changeoperation  vendor        joins\n",
       "97         fty_code  vendor        joins\n",
       "99          src_sys  vendor        joins"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#join key\n",
    "df_o.loc[df_o['table']=='vendor']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "43117017",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['vendor.vendor_grp_name AS vendor_group_name']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logics = []\n",
    "\n",
    "if (token == 'insert'):\n",
    "    logics.append(df_i.iloc[0]['logic'])\n",
    "    list_1 = df_i.loc[df_i['output_node'].str.isnumeric()]['logic'].to_list()\n",
    "else:\n",
    "    logics.append(df_i.iloc[0]['full source'])\n",
    "    list_1 = df_i.loc[df_i['output_node'].str.isnumeric()]['full source'].to_list()\n",
    "\n",
    "logics = logics + list_1\n",
    "logics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5f566b0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>field_name</th>\n",
       "      <th>table_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>vendor_grp_name</td>\n",
       "      <td>vendor</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        field_name table_name\n",
       "0  vendor_grp_name     vendor"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "column_f = []\n",
    "table_f = []\n",
    "\n",
    "for logic in logics:\n",
    "    \n",
    "    column_, table_ = obtain_list_column_table(logic)\n",
    "    column_f = column_f + column_\n",
    "    table_f = table_f + table_\n",
    "    \n",
    "dict = {'field_name': column_f, 'table_name': table_f} \n",
    "df_temp = pd.DataFrame(dict)\n",
    "df_temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "006528b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>table name</th>\n",
       "      <th>table component</th>\n",
       "      <th>logic</th>\n",
       "      <th>original table</th>\n",
       "      <th>schema</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>z</td>\n",
       "      <td>[fact_po_hdr, fact_po_dtl, fact_shp_hdr, fact_...</td>\n",
       "      <td>&lt;class 'sqlglot.expressions.Union'&gt;</td>\n",
       "      <td></td>\n",
       "      <td>[qma, qma, qma, qma, qma]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>vendor</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>dim_fty_supr</td>\n",
       "      <td>qma</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>factory</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>dim_fty_supr</td>\n",
       "      <td>qma</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>crc</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>mapping_crc_grouping</td>\n",
       "      <td>qma_datamart</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>managing_office</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>sp_managing_office_mapping</td>\n",
       "      <td>qma_datamart</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>factory_mapping</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>mapping_ngcv12_factory</td>\n",
       "      <td>qma_datamart</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        table name                                    table component  \\\n",
       "0                z  [fact_po_hdr, fact_po_dtl, fact_shp_hdr, fact_...   \n",
       "1           vendor                                                      \n",
       "2          factory                                                      \n",
       "3              crc                                                      \n",
       "4  managing_office                                                      \n",
       "5  factory_mapping                                                      \n",
       "\n",
       "                                 logic              original table  \\\n",
       "0  <class 'sqlglot.expressions.Union'>                               \n",
       "1                                                     dim_fty_supr   \n",
       "2                                                     dim_fty_supr   \n",
       "3                                             mapping_crc_grouping   \n",
       "4                                       sp_managing_office_mapping   \n",
       "5                                           mapping_ngcv12_factory   \n",
       "\n",
       "                      schema  \n",
       "0  [qma, qma, qma, qma, qma]  \n",
       "1                        qma  \n",
       "2                        qma  \n",
       "3               qma_datamart  \n",
       "4               qma_datamart  \n",
       "5               qma_datamart  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table_list, table_component, logic_type, original_table, table_schema = obtain_list_table_alias(sql)\n",
    "\n",
    "# Convert to DataFrame\n",
    "dict = {'table name': table_list, 'table component': table_component, 'logic': logic_type, 'original table': original_table, 'schema': table_schema} \n",
    "   \n",
    "table_alias = pd.DataFrame(dict)\n",
    "table_alias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5357b181",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>output_node</th>\n",
       "      <th>alias</th>\n",
       "      <th>reference node</th>\n",
       "      <th>logic</th>\n",
       "      <th>full source</th>\n",
       "      <th>column_l</th>\n",
       "      <th>table_l</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>vendor_group_name</td>\n",
       "      <td>vendor_group_name</td>\n",
       "      <td></td>\n",
       "      <td>vendor.vendor_grp_name AS vendor_group_name</td>\n",
       "      <td>SELECT vendor.vendor_grp_name AS vendor_group_...</td>\n",
       "      <td>[vendor_grp_name]</td>\n",
       "      <td>[vendor]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>vendor.vendor_grp_name</td>\n",
       "      <td>vendor</td>\n",
       "      <td></td>\n",
       "      <td>qma.dim_fty_supr AS vendor</td>\n",
       "      <td>qma.dim_fty_supr AS vendor</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              output_node              alias reference node  \\\n",
       "0       vendor_group_name  vendor_group_name                  \n",
       "1  vendor.vendor_grp_name             vendor                  \n",
       "\n",
       "                                         logic  \\\n",
       "0  vendor.vendor_grp_name AS vendor_group_name   \n",
       "1                   qma.dim_fty_supr AS vendor   \n",
       "\n",
       "                                         full source           column_l  \\\n",
       "0  SELECT vendor.vendor_grp_name AS vendor_group_...  [vendor_grp_name]   \n",
       "1                         qma.dim_fty_supr AS vendor                      \n",
       "\n",
       "    table_l  \n",
       "0  [vendor]  \n",
       "1            "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#clean up\n",
    "if (token=='insert'):\n",
    "    df_i['column_l'], df_i['table_l'] = zip(*df_i['logic'].map(obtain_list_column_table))\n",
    "    df_i.loc[df_i['logic']==df_i['full source'], 'column_l'] = ''\n",
    "    df_i.loc[df_i['logic']==df_i['full source'], 'table_l'] = ''\n",
    "elif (token=='update'):\n",
    "    df_i['column_l'], df_i['table_l'] = zip(*df_i['full source'].map(obtain_list_column_table))\n",
    "    df_i.loc[df_i['logic']==df_i['full source'], 'column_l'] = ''\n",
    "    df_i.loc[df_i['logic']==df_i['full source'], 'table_l'] = ''\n",
    "else:\n",
    "    print('no action.')\n",
    "    \n",
    "df_i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "5a0c0357",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>output_node</th>\n",
       "      <th>alias</th>\n",
       "      <th>reference node</th>\n",
       "      <th>logic</th>\n",
       "      <th>full source</th>\n",
       "      <th>column_l</th>\n",
       "      <th>table_l</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [output_node, alias, reference node, logic, full source, column_l, table_l]\n",
       "Index: []"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_mapping = df_i.loc[df_i['output_node']=='']\n",
    "df_mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "7dcfa983",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'table'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[132], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#merge field information to table information\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m df_field \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mmerge(df_temp, df_mapping, how\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mleft\u001b[39m\u001b[38;5;124m'\u001b[39m, left_on\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtable_name\u001b[39m\u001b[38;5;124m'\u001b[39m, right_on\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtable\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      3\u001b[0m df_field\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\pandas\\core\\reshape\\merge.py:110\u001b[0m, in \u001b[0;36mmerge\u001b[1;34m(left, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[0;32m     93\u001b[0m \u001b[38;5;129m@Substitution\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mleft : DataFrame or named Series\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     94\u001b[0m \u001b[38;5;129m@Appender\u001b[39m(_merge_doc, indents\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m     95\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmerge\u001b[39m(\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    108\u001b[0m     validate: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    109\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame:\n\u001b[1;32m--> 110\u001b[0m     op \u001b[38;5;241m=\u001b[39m _MergeOperation(\n\u001b[0;32m    111\u001b[0m         left,\n\u001b[0;32m    112\u001b[0m         right,\n\u001b[0;32m    113\u001b[0m         how\u001b[38;5;241m=\u001b[39mhow,\n\u001b[0;32m    114\u001b[0m         on\u001b[38;5;241m=\u001b[39mon,\n\u001b[0;32m    115\u001b[0m         left_on\u001b[38;5;241m=\u001b[39mleft_on,\n\u001b[0;32m    116\u001b[0m         right_on\u001b[38;5;241m=\u001b[39mright_on,\n\u001b[0;32m    117\u001b[0m         left_index\u001b[38;5;241m=\u001b[39mleft_index,\n\u001b[0;32m    118\u001b[0m         right_index\u001b[38;5;241m=\u001b[39mright_index,\n\u001b[0;32m    119\u001b[0m         sort\u001b[38;5;241m=\u001b[39msort,\n\u001b[0;32m    120\u001b[0m         suffixes\u001b[38;5;241m=\u001b[39msuffixes,\n\u001b[0;32m    121\u001b[0m         indicator\u001b[38;5;241m=\u001b[39mindicator,\n\u001b[0;32m    122\u001b[0m         validate\u001b[38;5;241m=\u001b[39mvalidate,\n\u001b[0;32m    123\u001b[0m     )\n\u001b[0;32m    124\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m op\u001b[38;5;241m.\u001b[39mget_result(copy\u001b[38;5;241m=\u001b[39mcopy)\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\pandas\\core\\reshape\\merge.py:703\u001b[0m, in \u001b[0;36m_MergeOperation.__init__\u001b[1;34m(self, left, right, how, on, left_on, right_on, axis, left_index, right_index, sort, suffixes, indicator, validate)\u001b[0m\n\u001b[0;32m    696\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cross \u001b[38;5;241m=\u001b[39m cross_col\n\u001b[0;32m    698\u001b[0m \u001b[38;5;66;03m# note this function has side effects\u001b[39;00m\n\u001b[0;32m    699\u001b[0m (\n\u001b[0;32m    700\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mleft_join_keys,\n\u001b[0;32m    701\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mright_join_keys,\n\u001b[0;32m    702\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mjoin_names,\n\u001b[1;32m--> 703\u001b[0m ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_merge_keys()\n\u001b[0;32m    705\u001b[0m \u001b[38;5;66;03m# validate the merge keys dtypes. We may need to coerce\u001b[39;00m\n\u001b[0;32m    706\u001b[0m \u001b[38;5;66;03m# to avoid incompatible dtypes\u001b[39;00m\n\u001b[0;32m    707\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_coerce_merge_keys()\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\pandas\\core\\reshape\\merge.py:1162\u001b[0m, in \u001b[0;36m_MergeOperation._get_merge_keys\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1160\u001b[0m rk \u001b[38;5;241m=\u001b[39m cast(Hashable, rk)\n\u001b[0;32m   1161\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m rk \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1162\u001b[0m     right_keys\u001b[38;5;241m.\u001b[39mappend(right\u001b[38;5;241m.\u001b[39m_get_label_or_level_values(rk))\n\u001b[0;32m   1163\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1164\u001b[0m     \u001b[38;5;66;03m# work-around for merge_asof(right_index=True)\u001b[39;00m\n\u001b[0;32m   1165\u001b[0m     right_keys\u001b[38;5;241m.\u001b[39mappend(right\u001b[38;5;241m.\u001b[39mindex)\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\pandas\\core\\generic.py:1850\u001b[0m, in \u001b[0;36mNDFrame._get_label_or_level_values\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1844\u001b[0m     values \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m   1845\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxes[axis]\n\u001b[0;32m   1846\u001b[0m         \u001b[38;5;241m.\u001b[39mget_level_values(key)  \u001b[38;5;66;03m# type: ignore[assignment]\u001b[39;00m\n\u001b[0;32m   1847\u001b[0m         \u001b[38;5;241m.\u001b[39m_values\n\u001b[0;32m   1848\u001b[0m     )\n\u001b[0;32m   1849\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1850\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key)\n\u001b[0;32m   1852\u001b[0m \u001b[38;5;66;03m# Check for duplicates\u001b[39;00m\n\u001b[0;32m   1853\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m values\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
      "\u001b[1;31mKeyError\u001b[0m: 'table'"
     ]
    }
   ],
   "source": [
    "#merge field information to table information\n",
    "df_field = pd.merge(df_temp, df_mapping, how='left', left_on='table_name', right_on='table')\n",
    "df_field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "b89bf4fd",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['schema', 'table', 'original_table', 'field'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[109], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m df_i[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124moutput_node\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlogic\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfull source\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcolumn_l\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtable_l\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mschema\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtable\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124moriginal_table\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124malias\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfield\u001b[39m\u001b[38;5;124m'\u001b[39m]]\n\u001b[0;32m      2\u001b[0m df_j \u001b[38;5;241m=\u001b[39m df_i\u001b[38;5;241m.\u001b[39mloc[df_i[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124moutput_node\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m==\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m      3\u001b[0m df_j \u001b[38;5;241m=\u001b[39m df_j[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mschema\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtable\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtable_alias\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124moriginal_table\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124malias\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfield\u001b[39m\u001b[38;5;124m'\u001b[39m]]\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\pandas\\core\\frame.py:3813\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3811\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n\u001b[0;32m   3812\u001b[0m         key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[1;32m-> 3813\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39m_get_indexer_strict(key, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m\"\u001b[39m)[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m   3815\u001b[0m \u001b[38;5;66;03m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[0;32m   3816\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(indexer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:6070\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[1;34m(self, key, axis_name)\u001b[0m\n\u001b[0;32m   6067\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   6068\u001b[0m     keyarr, indexer, new_indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[1;32m-> 6070\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_raise_if_missing(keyarr, indexer, axis_name)\n\u001b[0;32m   6072\u001b[0m keyarr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtake(indexer)\n\u001b[0;32m   6073\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Index):\n\u001b[0;32m   6074\u001b[0m     \u001b[38;5;66;03m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:6133\u001b[0m, in \u001b[0;36mIndex._raise_if_missing\u001b[1;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[0;32m   6130\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNone of [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] are in the [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   6132\u001b[0m not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[38;5;241m.\u001b[39mnonzero()[\u001b[38;5;241m0\u001b[39m]]\u001b[38;5;241m.\u001b[39munique())\n\u001b[1;32m-> 6133\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnot_found\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not in index\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mKeyError\u001b[0m: \"['schema', 'table', 'original_table', 'field'] not in index\""
     ]
    }
   ],
   "source": [
    "df_i[['output_node', 'logic', 'full source', 'column_l', 'table_l', 'schema', 'table', 'original_table', 'alias', 'field']]\n",
    "df_j = df_i.loc[df_i['output_node']=='']\n",
    "df_j = df_j[['schema', 'table', 'table_alias', 'original_table', 'alias', 'field']]\n",
    "\n",
    "df_z = pd.merge(df_temp, df_j, how='left', left_on = ['field_name', 'table_name'], right_on = ['field', 'table'])\n",
    "df_z.drop_duplicates(inplace=True)\n",
    "\n",
    "df_empty_table = df_z.loc[df_z['schema'].isna()]\n",
    "df_empty_table = pd.merge(df_empty_table[['field_name', 'table_name']], df_j, how='left', left_on = ['field_name'], right_on = ['field'])\n",
    "df_empty_table.drop_duplicates(inplace=True)\n",
    "\n",
    "#table field information\n",
    "df_z = df_z.loc[df_z['schema']=='']\n",
    "df_final = pd.concat([df_z, df_empty_table], ignore_index=True, axis=0)\n",
    "df_i.loc[df_i['output_node']!='']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d414c961",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlglot, string\n",
    "import sqlglot.expressions as s_ex\n",
    "\n",
    "def generate_aliases(ast):\n",
    "   '''\n",
    "   Take in the SQL AST and generate an infinite stream of possible alias names.\n",
    "   At each iteration, check if the candidate name does not already exist in the AST\n",
    "   '''\n",
    "   ignore = [i.this for i in ast.find_all(s_ex.Identifier)]\n",
    "   q = ['']\n",
    "   while q:\n",
    "     if(current:=q.pop(0)) not in ignore and current: yield current\n",
    "     for i in string.ascii_lowercase: q += [current + i]\n",
    "\n",
    "def add_aliases(tree, alias_stream, default_scope = None, scopes = {}):\n",
    "   def handle_subquery(subquery):\n",
    "      # function to add alias to subqueries in \"from\" clause\n",
    "      if not subquery.alias:\n",
    "         subquery.args['alias'] = s_ex.TableAlias(this = s_ex.to_identifier(next(alias_stream)))\n",
    "      add_aliases(subquery.this, alias_stream, default_scope, scopes)\n",
    "   def handle_table(root):\n",
    "      # function to add alias to table specified in \"from\" clause\n",
    "      scopes[root.this.this] = root.alias if root.alias else next(alias_stream)\n",
    "      if not root.alias:\n",
    "          root.args['alias'] = s_ex.TableAlias(this = s_ex.to_identifier(scopes[root.this.this]))\n",
    "          return root.this.this\n",
    "   if isinstance(tree, s_ex.Select): # check if tree is a select statement\n",
    "      if isinstance(root:=tree.args['from'].this, s_ex.Table):\n",
    "          # if the \"from\" clause is a table, add alias (if one does not exist)\n",
    "          default_scope = handle_table(root)\n",
    "      elif isinstance(root, s_ex.Subquery):\n",
    "          # if the \"from\" clause is a subquery, add an alias and traverse it\n",
    "          handle_subquery(root)\n",
    "      for i in tree.args.get('joins', []):\n",
    "          #loop over all table joins, adding aliases and traversing\n",
    "          if isinstance(i.this, s_ex.Table):\n",
    "             _ = handle_table(i.this)\n",
    "          else:\n",
    "             handle_subquery(i.this)\n",
    "   if isinstance(tree, s_ex.Column):\n",
    "      # check if column reference has an alias. If not, add one\n",
    "      if 'table' not in tree.args:\n",
    "         tree.args['table'] = s_ex.to_identifier(default_scope if default_scope is not None else next(alias_stream))\n",
    "      tree.args['table'] = s_ex.to_identifier(scopes.get(tree.args['table'].this, tree.args['table'].this))\n",
    "   for i, a in enumerate(tree.args.get('expressions', [])):\n",
    "      if not isinstance(a, sqlglot.expressions.Column) and isinstance(tree, s_ex.Select):\n",
    "         # check that expression, such as a + b or my_fun(a, b) has an alias\n",
    "         # if not, add an alias\n",
    "         tree.args['expressions'][i] = s_ex.Alias(this = a, alias = next(alias_stream))\n",
    "      add_aliases(a, alias_stream, default_scope, scopes)\n",
    "   for a, b in getattr(tree, 'args', {}).items():\n",
    "      # traverse the rest of the tree\n",
    "      if a not in ['from', 'expressions']:\n",
    "         for i in ([b] if not isinstance(b, list) else b):\n",
    "             if not isinstance(i, s_ex.Expression): continue\n",
    "             add_aliases(i, alias_stream, default_scope, scopes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88ee3134",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_cosette(s):\n",
    "    ast = sqlglot.parse(s)[0]\n",
    "    add_aliases(ast, generate_aliases(ast))\n",
    "    return ast.sql()\n",
    "\n",
    "s1 = \"\"\"\n",
    " select a, b, c from tbl where a > 1\n",
    "\"\"\"\n",
    "s2 = \"\"\"\n",
    " select a, count(*) from tbl where my_fun(b + 1) > a + 3 group by a\n",
    "\"\"\"\n",
    "s3 = \"\"\"\n",
    " select tbl1.a + tbl2.b * 2, from tbl1 join tbl2 on tbl1.c = tbl2.d\n",
    "\"\"\"\n",
    "s4 = \"\"\"\n",
    " select a + 1 from (select 1 from generate_series(1, 10, 1)) order by a\n",
    "\"\"\"\n",
    "s5 = \"\"\"\n",
    "select name, sum(status in ('. On', '. Off')) from tbl group by name\n",
    "\"\"\"\n",
    "s6 = \"\"\"\n",
    "with cte as (\n",
    "  select employee_id, starttime, max(endtime) from time_records\n",
    "  group by employee_id, starttime\n",
    ")\n",
    "select employee_id, starttime, m, array_agg(id)\n",
    "from cte join time_records on cte.starttime <= time_records.starttime and time_records.endtime <= cte.m\n",
    "where not exists (select 1 from cte where employee_id = employee_id and starttime < starttime and m <= m)\n",
    "group by employee_id, starttime, m\n",
    "\"\"\"\n",
    "\n",
    "print(to_cosette(sql))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57d4e738",
   "metadata": {},
   "outputs": [],
   "source": [
    "sql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5b51644",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
