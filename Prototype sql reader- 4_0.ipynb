{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "0a9a1c6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sqlparse in c:\\users\\elam2\\appdata\\roaming\\python\\python311\\site-packages (0.5.1)\n",
      "Requirement already satisfied: sqlglot in c:\\users\\elam2\\appdata\\roaming\\python\\python311\\site-packages (25.16.1)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "!pip install sqlparse --user --upgrade\n",
    "!pip install sqlglot --user --upgrade\n",
    "\n",
    "import sqlparse\n",
    "\n",
    "import sqlglot\n",
    "import sqlglot.expressions as exp\n",
    "from sqlglot import parse_one\n",
    "from sqlglot.optimizer import optimize\n",
    "from sqlglot import optimizer\n",
    "from sqlglot.errors import OptimizeError\n",
    "from sqlglot import lineage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "5fea6528",
   "metadata": {},
   "outputs": [],
   "source": [
    "#helper functions\n",
    "#find all alias from cte and related table and schema\n",
    "def obtain_table_alias_type(sql):\n",
    "    \n",
    "    for alias in parse_one(sql, dialect=\"redshift\").find_all(exp.TableAlias):\n",
    "        \n",
    "        print(f\"alias => {alias.this.this} | alias_table_type => {type(alias.parent_select)}\" )\n",
    "        \n",
    "        break\n",
    "        \n",
    "#find schema by name\n",
    "def find_schema_by_table_name(sql, table_name):\n",
    "    \n",
    "    for table in parse_one(sql, dialect=\"redshift\").find_all(exp.Table):\n",
    "        \n",
    "        if (table_name == table.name):\n",
    "            return str(table.args['db'])\n",
    "            \n",
    "def obtain_list_column_table(sql):\n",
    "    \n",
    "    column_l = []\n",
    "    table_l = []\n",
    "    alias_l = []\n",
    "    \n",
    "    for column in parse_one(sql, dialect=\"redshift\").find_all(exp.Column):\n",
    "        \n",
    "        column_l.append(column.name)\n",
    "        table_l.append(column.table)\n",
    "        #print(column.key)\n",
    "        #print(f\"Column => {column.name} | DB => {column.table}\" )\n",
    "    \n",
    "    #in case none of the field has table information, the only table in the sql will be the source table\n",
    "    if(all(elem == '' for elem in table_l)):\n",
    "        \n",
    "        tablename = ''\n",
    "        \n",
    "        for table in parse_one(sql, dialect=\"redshift\").find_all(exp.Table):\n",
    "            \n",
    "            if(table.name != ''):\n",
    "                tablename = table.name\n",
    "    \n",
    "        for n in range(len(table_l)):\n",
    "        \n",
    "            table_l[n] = tablename\n",
    "    \n",
    "    return column_l, table_l\n",
    "\n",
    "#find all alias from cte and related table and schema\n",
    "def obtain_list_table_alias(sql):\n",
    "    \n",
    "    unalias_name = []\n",
    "    alias_l = []\n",
    "    related_table_l = []\n",
    "    alias_type_ = []\n",
    "    schema_l = []\n",
    "    \n",
    "    for alias in parse_one(sql, dialect=\"redshift\").find_all(exp.TableAlias):\n",
    "        \n",
    "        table_t = []\n",
    "        #if it is cte\n",
    "        if (alias.parent.name == ''):\n",
    "            alias_type_.append(type(alias.parent.args['this']))\n",
    "            alias_l.append(alias.this.this)\n",
    "            column_t, table_t = obtain_list_column_table(str(alias.parent))\n",
    "            related_table_l.append(list(dict.fromkeys(table_t)))\n",
    "            unalias_name.append(alias.parent.name)\n",
    "            \n",
    "            schema = []\n",
    "            \n",
    "            for table in list(dict.fromkeys(table_t)):\n",
    "                \n",
    "                schema.append(find_schema_by_table_name(sql, table))\n",
    "                \n",
    "            schema_l.append(schema)\n",
    "            \n",
    "        #if it is normal table\n",
    "        else:\n",
    "            alias_type_.append('')\n",
    "            related_table_l.append('')\n",
    "            alias_l.append(alias.this.this)\n",
    "            unalias_name.append(alias.parent.name)\n",
    "            \n",
    "            schema_l.append(find_schema_by_table_name(sql, alias.parent.name))\n",
    "        \n",
    "        #print(f\"Column => {alias_l} | DB => {related_table_l}\" )\n",
    "        \n",
    "    return alias_l, related_table_l, alias_type_, unalias_name, schema_l\n",
    "\n",
    "def find_column_originated(sql):\n",
    "\n",
    "    column_l = []\n",
    "    table_l = []\n",
    "    originated_l = []\n",
    "    \n",
    "    group_column_l = []\n",
    "    group_table_l = []\n",
    "    group_originated_l = []\n",
    "    #print(sql)\n",
    "    \n",
    "    #need to use parse instead of parse_one\n",
    "    for expression in sqlglot.parse(sql):\n",
    "        #print(expression.args)\n",
    "        \n",
    "        keysList = list(expression.args.keys())\n",
    "        #print(keysList)\n",
    "    \n",
    "        for key in keysList:\n",
    "            if expression.args[key] != None:\n",
    "                \n",
    "                #find all expression/join key\n",
    "                if type(expression.args[key]) is list:\n",
    "                    for objecto in expression.args[key]:\n",
    "                        for column in objecto.find_all(exp.Column):\n",
    "                            #print(f\"Column => {column.name} | type => {key}\" )\n",
    "                            column_l.append(column.name)\n",
    "                            table_l.append(column.table)\n",
    "                            originated_l.append(key)\n",
    "                else:\n",
    "                    #list all group by items\n",
    "                    if key == 'group':\n",
    "                        for groupby_clause in expression.args[key].expressions:\n",
    "                            if (type(groupby_clause)==sqlglot.expressions.Column):\n",
    "                                group_column_l.append(groupby_clause.this)\n",
    "                                group_table_l.append(groupby_clause.table)\n",
    "                            else:\n",
    "                                group_column_l.append(groupby_clause)\n",
    "                                group_table_l.append(None)\n",
    "                            group_originated_l.append('group by')\n",
    "    \n",
    "    #combine into one single dataframe\n",
    "    dict = {'output_column': column_l, 'table': table_l, 'action': originated_l} \n",
    "    df_relationship = pd.DataFrame(dict)\n",
    "    dict = {'output_column': group_column_l, 'table': group_table_l, 'action': group_originated_l}\n",
    "    df_group = pd.DataFrame(dict)\n",
    "    df_relationship = df_relationship.append(df_group)\n",
    "    \n",
    "    return df_relationship\n",
    "\n",
    "#just in case if there is union\n",
    "def deep_find_column_originated(sql, table_name):\n",
    "    \n",
    "    sqlglot_ = parse_one(sql)\n",
    "    if (type(sqlglot_)==sqlglot.expressions.Union):\n",
    "        df_union_1 = find_column_originated(str(sqlglot_.args['this']))\n",
    "        df_union_2 = find_column_originated(str(sqlglot_.args['expression']))\n",
    "        \n",
    "        df_union_1['union'] = ' left union'\n",
    "        df_union_2['union'] = ' right union'\n",
    "        \n",
    "        df_ = pd.concat([df_union_1, df_union_2], ignore_index=True)\n",
    "        \n",
    "    else:\n",
    "        df_ = find_column_originated(sql)\n",
    "        df_['union'] = None\n",
    "        \n",
    "    df_['destined_table'] = table_name\n",
    "    return df_ \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "f756be32",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sql restructuring helper functions\n",
    "def sql_restructuring(sql):\n",
    "    \n",
    "    token = ''\n",
    "    \n",
    "    statement = sqlparse.parse(sql)[0]\n",
    "    print(statement.get_type())\n",
    "    #print(statement)\n",
    "    \n",
    "    if (statement.get_type() == \"INSERT\" or statement.get_type() == \"CREATE\"):\n",
    "\n",
    "        token = 'insert'\n",
    "\n",
    "        for expression in sqlglot.parse(sql):\n",
    "            table_name = str(expression.args['this'].this)\n",
    "            columns = []\n",
    "            for column in expression.args['this'].expressions:\n",
    "                columns.append(str(column))\n",
    "            expression_ = str(expression.expression)\n",
    "\n",
    "        #recompose the list of column into a single string: REAL Columns for the datamart\n",
    "        all_column = columns\n",
    "\n",
    "        sql = expression_\n",
    "        #print(sql)\n",
    "\n",
    "    elif(statement.get_type() == \"UPDATE\"):\n",
    "\n",
    "        token = 'update'\n",
    "\n",
    "        for expression in sqlglot.parse(sql):\n",
    "            #print(expression.args)\n",
    "            table_name = str(expression.args['this'])\n",
    "            field_value_name = expression.expressions\n",
    "\n",
    "            fieldname = []\n",
    "            value = []\n",
    "\n",
    "            for pair in field_value_name:\n",
    "                fieldname.append(str(pair.this))\n",
    "                value.append(str(pair.expression))\n",
    "\n",
    "            from_ = str(expression.args['from'])\n",
    "            where = str(expression.args['where'])\n",
    "\n",
    "            sql_ = ''\n",
    "\n",
    "            for value_, fieldname_ in zip(value, fieldname):\n",
    "\n",
    "                sql_ = sql_ + ' ' + value_ + ' AS ' + fieldname_ + ','\n",
    "\n",
    "            sql_ = sql_[:-1]\n",
    "\n",
    "            sql_ = 'SELECT ' + sql_ + ' FROM ' + table_name + ' JOIN ' + from_.replace('FROM', ' ', 1) + ' ON (' + where.replace('WHERE', ' ', 1) + ')' \n",
    "            sql = sql_\n",
    "\n",
    "            update_column = fieldname\n",
    "            all_column = update_column\n",
    "    \n",
    "    elif(statement.get_type() == \"SELECT\"):\n",
    "        \n",
    "        token='select'\n",
    "        \n",
    "        all_column = []\n",
    "        \n",
    "        for expression in sqlglot.parse(sql):\n",
    "            table_name = str(expression.args['from'].this)\n",
    "        \n",
    "        for expression in sqlglot.parse_one(sql):\n",
    "            all_column.append(expression.args['this'].this)\n",
    "            \n",
    "        sql = sql\n",
    "    \n",
    "    else:\n",
    "        print(\"can't define the sql type\")\n",
    "        all_column = ''\n",
    "        table_name = ''\n",
    "        sql = 'Invalid'\n",
    "        token = 'Invalid'\n",
    "        \n",
    "        \n",
    "    return all_column, sql, token, table_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "a5d40651",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print column level leneage dataframe when given a column name from a given sql\n",
    "\n",
    "def column_lineage(column, sql, token):\n",
    "\n",
    "    node_list = []\n",
    "    source_list = []\n",
    "    expression_list = []\n",
    "    column_list = []\n",
    "    alias_list = []\n",
    "    reference_list = []\n",
    "\n",
    "    for node in lineage.lineage(column, sql).walk():\n",
    "\n",
    "        node_ = str(node.name)\n",
    "\n",
    "        #print(node_)\n",
    "        source = str(node.source)\n",
    "        alias = str(node.expression.alias)\n",
    "        expression = str(node.expression)\n",
    "        #depth = expression.depth\n",
    "\n",
    "        #full source\n",
    "        node_list.append(column)\n",
    "        source_list.append(source)\n",
    "        alias_list.append(alias)\n",
    "        expression_list.append(expression)\n",
    "        column_list.append(node_)\n",
    "        reference_list.append(node.reference_node_name)\n",
    "\n",
    "    # Convert to DataFrame\n",
    "    dict = {'node': node_list, 'output_node': column_list, 'alias': alias_list, 'reference node': reference_list, 'logic': expression_list, 'full source': source_list} \n",
    "\n",
    "    df_i = pd.DataFrame(dict)\n",
    "    df_i.iloc[0, 3] = 'main'\n",
    "    \n",
    "    #determine all table and column relationship\n",
    "    logics = []\n",
    "\n",
    "    if (token == 'insert'):\n",
    "        logics.append(df_i.iloc[0]['logic'])\n",
    "        list_1 = df_i.loc[df_i['output_node'].str.isnumeric()]['logic'].to_list()\n",
    "    else:\n",
    "        logics.append(df_i.iloc[0]['full source'])\n",
    "        list_1 = df_i.loc[df_i['output_node'].str.isnumeric()]['full source'].to_list()\n",
    "\n",
    "    logics = logics + list_1\n",
    "    \n",
    "    column_f = []\n",
    "    table_f = []\n",
    "\n",
    "    for logic in logics:\n",
    "\n",
    "        column_, table_ = obtain_list_column_table(logic)\n",
    "        column_f = column_f + column_\n",
    "        table_f = table_f + table_\n",
    "\n",
    "    dict = {'field_name': column_f, 'table_name': table_f} \n",
    "    df_temp = pd.DataFrame(dict)\n",
    "    df_temp\n",
    "\n",
    "    table_list, table_component, logic_type, original_table, table_schema = obtain_list_table_alias(sql)\n",
    "\n",
    "    # Convert to DataFrame\n",
    "    dict = {'table_name': table_list, 'table component': table_component, 'logic': logic_type, 'original table': original_table, 'schema': table_schema} \n",
    "\n",
    "    table_alias = pd.DataFrame(dict)\n",
    "    table_mapping = pd.merge(df_temp, table_alias, how='left', on='table_name')\n",
    "    table_mapping = table_mapping[['table_name', 'table component', 'logic', 'original table', 'schema']]\n",
    "    table_mapping = table_mapping[~table_mapping.astype(str).duplicated()]\n",
    "    \n",
    "    #clean up\n",
    "    if (token=='insert'):\n",
    "        df_i['column_l'], df_i['table_l'] = zip(*df_i['logic'].map(obtain_list_column_table))\n",
    "        df_i.loc[df_i['logic']==df_i['full source'], 'column_l'] = ''\n",
    "        df_i.loc[df_i['logic']==df_i['full source'], 'table_l'] = ''\n",
    "    elif (token=='update'):\n",
    "        df_i['column_l'], df_i['table_l'] = zip(*df_i['full source'].map(obtain_list_column_table))\n",
    "        df_i.loc[df_i['logic']==df_i['full source'], 'column_l'] = ''\n",
    "        df_i.loc[df_i['logic']==df_i['full source'], 'table_l'] = ''\n",
    "    else:\n",
    "        print('no action.')\n",
    "\n",
    "    #make a list of all component of a node \n",
    "    main_df = df_i.loc[df_i['reference node']!='']\n",
    "    main_df = main_df.explode(['column_l', 'table_l'])\n",
    "    main_df['subnode'] = main_df['table_l'] + '.' + main_df['column_l']\n",
    "\n",
    "    #produce field dictionary\n",
    "    df_i.loc[df_i['output_node'].str.isnumeric(), 'output_node'] = df_i['reference node'] + '.' + df_i['alias']\n",
    "    df_field = df_i[['output_node', 'logic']].drop_duplicates(ignore_index=True)\n",
    "    df_field = df_field.rename(columns={\"output_node\": \"field\", \"logic\": \"original field\",}, errors=\"raise\")\n",
    "    \n",
    "    #final table cleaning\n",
    "    final_df = pd.merge(main_df, df_field, how='left', left_on='subnode', right_on='field')\n",
    "    final_df = final_df[['node', 'output_node', 'alias', 'reference node', 'logic', 'full source', 'table_l', 'column_l', 'original field']]\n",
    "\n",
    "    final_df = pd.merge(final_df, table_mapping, how='left', left_on='table_l', right_on='table_name')\n",
    "    \n",
    "    final_df['original field'] = final_df['original field'].fillna('noSchema')\n",
    "    final_df.loc[:, 'temp_schema'] = final_df['original field'].map(lambda x: x.split('.')[0])\n",
    "    final_df.loc[final_df['table component'].isna(), 'schema'] = final_df['temp_schema']\n",
    "    final_df.loc[final_df['table component'].isna(), 'original table'] = final_df['table_name']\n",
    "\n",
    "    final_df = final_df[['node', 'reference node', 'alias', 'logic_x', \n",
    "              'full source', 'schema', 'table_l', 'table component', 'original table', 'column_l']].fillna('')\n",
    "    \n",
    "    return final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "c3e548b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sp_column_lineage_relationship(sql_list, file_name):\n",
    "\n",
    "    overall_df_relation = pd.DataFrame()\n",
    "    overall_lineage = pd.DataFrame()\n",
    "\n",
    "    n = 0\n",
    "\n",
    "    for sql in sql_list:\n",
    "        \n",
    "        try: \n",
    "            #beautify sql by removing all comments\n",
    "            sql = sqlparse.format(sql, strip_comments=True).strip()\n",
    "\n",
    "            #prepocessing\n",
    "            #change update and insert to respective select statement to fit in the format of sqlglot\n",
    "            #prepare list of output table columns\n",
    "            all_column, sql, token, table_name = sql_restructuring(sql)\n",
    "\n",
    "            #print(f'after restructuring: {sql}')\n",
    "            \n",
    "            if (sql!=''):\n",
    "                #print(all_column)\n",
    "                #find the position of the column in the sql, whether it is in select/update/insert or join clause or group by\n",
    "                df_relation = deep_find_column_originated(sql, table_name)\n",
    "\n",
    "                for subquery in parse_one(sql).find_all(exp.Subquery):\n",
    "\n",
    "                    df_subquery = deep_find_column_originated(str(subquery.args['this']), subquery.alias)\n",
    "                    df_relation = pd.concat([df_relation, df_subquery], ignore_index=True)\n",
    "\n",
    "                groupby_df = df_relation.loc[df_relation['action']=='group by']\n",
    "                column_df = df_relation.loc[df_relation['action']=='expressions']\n",
    "                join_df = df_relation.loc[df_relation['action']=='joins']\n",
    "\n",
    "                lineage_df = pd.DataFrame()\n",
    "\n",
    "                for column in all_column:\n",
    "                    print(column)\n",
    "                    #print(f'before obtaining cll: {sql}')\n",
    "                    temp_df = column_lineage(column, sql, token)\n",
    "                    temp_df['row_count'] = temp_df.shape[0]\n",
    "                    lineage_df = pd.concat([lineage_df, temp_df], ignore_index=True)\n",
    "\n",
    "                df_relation['sql_num'] = n\n",
    "                lineage_df['sql_num'] = n\n",
    "                overall_df_relation = pd.concat([overall_df_relation, df_relation], ignore_index=True)\n",
    "                overall_lineage = pd.concat([overall_lineage, lineage_df], ignore_index=True)\n",
    "\n",
    "                n = n+1\n",
    "        \n",
    "        except Exception as ex:\n",
    "            raise Exception('Message error: ' + str(ex))\n",
    "\n",
    "    # create a excel writer object\n",
    "    with pd.ExcelWriter(file_name + \".xlsx\") as writer:\n",
    "\n",
    "        # use to_excel function and specify the sheet_name and index \n",
    "        # to store the dataframe in specified sheet\n",
    "        overall_df_relation.to_excel(writer, sheet_name=\"Relationships\", index=False)\n",
    "        overall_lineage.to_excel(writer, sheet_name=\"Lineage\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "8c6e9f29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stored procedure\\sp_otp_po_cut_level.txt\n",
      "filename is sp_otp_po_cut_level.\n",
      "there are: 53 lines.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Format argument unsupported for TO_CHAR/TO_VARCHAR function\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INSERT\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ELAM2\\AppData\\Local\\Temp\\ipykernel_48232\\2988931172.py:135: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_relationship = df_relationship.append(df_group)\n",
      "C:\\Users\\ELAM2\\AppData\\Local\\Temp\\ipykernel_48232\\2988931172.py:135: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_relationship = df_relationship.append(df_group)\n",
      "C:\\Users\\ELAM2\\AppData\\Local\\Temp\\ipykernel_48232\\2988931172.py:135: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_relationship = df_relationship.append(df_group)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "COUNTRY_OF_ORIGIN\n",
      "PO_CUT\n",
      "STYLE\n",
      "COLOR\n",
      "STYLE_DESCRIPTION\n",
      "GOODS_DESCRIPTION\n",
      "PO_ISSUE_DATE\n",
      "ORIGINAL_CRD_AT_ORIGIN\n",
      "REVISED_CRD_AT_ORIGIN\n",
      "ACTUAL_CRD_AT_ORIGIN\n",
      "LOCAL_CURRENCY\n",
      "SEASON\n",
      "SOURCING_OFFICE\n",
      "SOURCE_SYSTEM\n",
      "DC_CODE\n",
      "PO_TYPE\n",
      "PURCHASING_GROUP\n",
      "SBU\n",
      "SUB_SBU\n",
      "PRODUCT_LINE\n",
      "PURCHASING_COMPANY\n",
      "VENDOR_FFC\n",
      "VENDOR_GROUP_NAME\n",
      "FACTORY_FFC\n",
      "DELAY_REASON\n",
      "SHIPMENT_TERMS\n",
      "PO_LOCATION\n",
      "VENDOR_NAME\n",
      "FACTORY_NAME\n",
      "REPORT_ORDER_QTY_LUM\n",
      "ORDER_AMOUNT_LOCAL_CURRENCY\n",
      "SHIPPED_QTY_LUM\n",
      "SHIPPED_AMT_LOCAL_CURRENCY\n",
      "BOOKED_QTY_LUM\n",
      "BOOKED_AMT_LOCAL_CURRENCY\n",
      "EFFECTIVE_QTY\n",
      "isSample\n",
      "isCustomOrder\n",
      "MANAGING_OFFICE\n",
      "CURRENT_DATE_\n",
      "src_sys\n",
      "MISC3\n",
      "MISC26\n",
      "MISC33\n",
      "PURCHASING_COMPANY_CODE\n",
      "exch_rate_date\n",
      "od_misc_flag\n",
      "tbr_defect_flag\n",
      "po_creation_date\n",
      "shipment_id\n",
      "hts_code\n",
      "factory_designation\n",
      "ERP_Factory_Code\n",
      "ERP_Vendor_Code\n",
      "PO_Season\n",
      "Revised_In_DC_Date\n",
      "Ship_Mode\n",
      "PO_Acknowledgement_Date\n",
      "PO_Complete_Status\n",
      "Greenlight_date\n",
      "First_Shipment_ID\n",
      "First_Actual_crd\n",
      "master_po\n",
      "freight_paid_by\n",
      "exit_cnty_port\n",
      "ship_to_name\n",
      "Brand_Requested_in_DC_date\n",
      "Original_Requested_Production_End_Date\n",
      "Latest_confirmed_Production_End_Date\n",
      "Buy_Month\n",
      "requested_delivery_date\n",
      "PO_closure_Eligibility\n",
      "Discharge_at_Port_of_Destination\n",
      "season_cleaned\n",
      "UPDATE\n",
      "VF_Est_DC_Arrival_Date\n",
      "ASN_Released_to_3PL\n",
      "UPDATE\n",
      "ASN_Released_to_3PL\n",
      "UPDATE\n",
      "Container_Number\n",
      "UPDATE\n",
      "Container_Number\n",
      "UPDATE\n",
      "sub_sbu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ELAM2\\AppData\\Local\\Temp\\ipykernel_48232\\2988931172.py:135: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_relationship = df_relationship.append(df_group)\n",
      "C:\\Users\\ELAM2\\AppData\\Local\\Temp\\ipykernel_48232\\2988931172.py:135: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_relationship = df_relationship.append(df_group)\n",
      "C:\\Users\\ELAM2\\AppData\\Local\\Temp\\ipykernel_48232\\2988931172.py:135: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_relationship = df_relationship.append(df_group)\n",
      "C:\\Users\\ELAM2\\AppData\\Local\\Temp\\ipykernel_48232\\2988931172.py:135: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_relationship = df_relationship.append(df_group)\n",
      "C:\\Users\\ELAM2\\AppData\\Local\\Temp\\ipykernel_48232\\2988931172.py:135: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_relationship = df_relationship.append(df_group)\n",
      "C:\\Users\\ELAM2\\AppData\\Local\\Temp\\ipykernel_48232\\2988931172.py:135: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_relationship = df_relationship.append(df_group)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sbu\n",
      "product_line\n",
      "misc3\n",
      "UPDATE\n",
      "BRAND\n",
      "MAJOR_PRODUCT_CATEGORY_NAME\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ELAM2\\AppData\\Local\\Temp\\ipykernel_48232\\2988931172.py:135: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_relationship = df_relationship.append(df_group)\n",
      "C:\\Users\\ELAM2\\AppData\\Local\\Temp\\ipykernel_48232\\2988931172.py:135: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_relationship = df_relationship.append(df_group)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BUSINESS_UNIT\n",
      "BRAND2\n",
      "MARKET\n",
      "PRODUCT_SUPPLY_GROUP\n",
      "UPDATE\n",
      "brand\n",
      "UPDATE\n",
      "exchange_rate\n",
      "UPDATE\n",
      "exchange_rate\n",
      "UPDATE\n",
      "certified_pocut_flag\n",
      "certprintdate\n",
      "UPDATE\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ELAM2\\AppData\\Local\\Temp\\ipykernel_48232\\2988931172.py:135: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_relationship = df_relationship.append(df_group)\n",
      "C:\\Users\\ELAM2\\AppData\\Local\\Temp\\ipykernel_48232\\2988931172.py:135: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_relationship = df_relationship.append(df_group)\n",
      "C:\\Users\\ELAM2\\AppData\\Local\\Temp\\ipykernel_48232\\2988931172.py:135: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_relationship = df_relationship.append(df_group)\n",
      "C:\\Users\\ELAM2\\AppData\\Local\\Temp\\ipykernel_48232\\2988931172.py:135: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_relationship = df_relationship.append(df_group)\n",
      "C:\\Users\\ELAM2\\AppData\\Local\\Temp\\ipykernel_48232\\2988931172.py:135: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_relationship = df_relationship.append(df_group)\n",
      "C:\\Users\\ELAM2\\AppData\\Local\\Temp\\ipykernel_48232\\2988931172.py:135: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_relationship = df_relationship.append(df_group)\n",
      "C:\\Users\\ELAM2\\AppData\\Local\\Temp\\ipykernel_48232\\2988931172.py:135: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_relationship = df_relationship.append(df_group)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "table_names\n",
      "ORDER_AMOUNT_USD\n",
      "SHIPPED_AMT_USD\n",
      "UNIT_PRICE\n",
      "EFFECTIVE_CRD\n",
      "fob_price_usd\n",
      "UPDATE\n",
      "Unit_Price_Average_in_USD\n",
      "UPDATE\n",
      "effective_crd_year\n",
      "effective_crd_month\n",
      "UPDATE\n",
      "days_late\n",
      "UPDATE\n",
      "ORDER_TYPE_CALCULATED\n",
      "BOOKED_AMT_USD\n",
      "EFFECTIVE_AMT_USD\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ELAM2\\AppData\\Local\\Temp\\ipykernel_48232\\2988931172.py:135: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_relationship = df_relationship.append(df_group)\n",
      "C:\\Users\\ELAM2\\AppData\\Local\\Temp\\ipykernel_48232\\2988931172.py:135: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_relationship = df_relationship.append(df_group)\n",
      "C:\\Users\\ELAM2\\AppData\\Local\\Temp\\ipykernel_48232\\2988931172.py:135: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_relationship = df_relationship.append(df_group)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UPDATE\n",
      "crc_code\n",
      "crc_description\n",
      "UPDATE\n",
      "CRC_Owner\n",
      "UPDATE\n",
      "crc_code\n",
      "crc_description\n",
      "UPDATE\n",
      "CRC_Owner\n",
      "UPDATE\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ELAM2\\AppData\\Local\\Temp\\ipykernel_48232\\2988931172.py:135: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_relationship = df_relationship.append(df_group)\n",
      "C:\\Users\\ELAM2\\AppData\\Local\\Temp\\ipykernel_48232\\2988931172.py:135: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_relationship = df_relationship.append(df_group)\n",
      "C:\\Users\\ELAM2\\AppData\\Local\\Temp\\ipykernel_48232\\2988931172.py:135: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_relationship = df_relationship.append(df_group)\n",
      "C:\\Users\\ELAM2\\AppData\\Local\\Temp\\ipykernel_48232\\2988931172.py:135: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_relationship = df_relationship.append(df_group)\n",
      "C:\\Users\\ELAM2\\AppData\\Local\\Temp\\ipykernel_48232\\2988931172.py:135: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_relationship = df_relationship.append(df_group)\n",
      "C:\\Users\\ELAM2\\AppData\\Local\\Temp\\ipykernel_48232\\2988931172.py:135: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_relationship = df_relationship.append(df_group)\n",
      "C:\\Users\\ELAM2\\AppData\\Local\\Temp\\ipykernel_48232\\2988931172.py:135: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_relationship = df_relationship.append(df_group)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "balance_qty\n",
      "UPDATE\n",
      "dc_name\n",
      "destination_country\n",
      "UPDATE\n",
      "Shipment_Status\n",
      "fr_release\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ELAM2\\AppData\\Local\\Temp\\ipykernel_48232\\2988931172.py:135: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_relationship = df_relationship.append(df_group)\n",
      "C:\\Users\\ELAM2\\AppData\\Local\\Temp\\ipykernel_48232\\2988931172.py:135: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_relationship = df_relationship.append(df_group)\n",
      "C:\\Users\\ELAM2\\AppData\\Local\\Temp\\ipykernel_48232\\2988931172.py:135: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_relationship = df_relationship.append(df_group)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shipment_id_closing_date\n",
      "Actual_Ship_Date\n",
      "First_Actual_Ship_Date\n",
      "UPDATE\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ELAM2\\AppData\\Local\\Temp\\ipykernel_48232\\2988931172.py:135: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_relationship = df_relationship.append(df_group)\n",
      "C:\\Users\\ELAM2\\AppData\\Local\\Temp\\ipykernel_48232\\2988931172.py:135: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_relationship = df_relationship.append(df_group)\n",
      "C:\\Users\\ELAM2\\AppData\\Local\\Temp\\ipykernel_48232\\2988931172.py:135: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_relationship = df_relationship.append(df_group)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shipment_Closed_By\n",
      "UPDATE\n",
      "hts_product_category\n",
      "hts_product_type\n",
      "UPDATE\n",
      "hts_product_category\n",
      "UPDATE\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ELAM2\\AppData\\Local\\Temp\\ipykernel_48232\\2988931172.py:135: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_relationship = df_relationship.append(df_group)\n",
      "C:\\Users\\ELAM2\\AppData\\Local\\Temp\\ipykernel_48232\\2988931172.py:135: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_relationship = df_relationship.append(df_group)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "costing_season\n",
      "UPDATE\n",
      "orders_to_be_produced_qty\n",
      "orders_to_be_produced_amt_usd\n",
      "actual_produced_qty\n",
      "actual_produced_amt_usd\n",
      "UPDATE\n",
      "fob_duties_rate\n",
      "UPDATE\n",
      "fob_duties_rate\n",
      "UPDATE\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ELAM2\\AppData\\Local\\Temp\\ipykernel_48232\\2988931172.py:135: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_relationship = df_relationship.append(df_group)\n",
      "C:\\Users\\ELAM2\\AppData\\Local\\Temp\\ipykernel_48232\\2988931172.py:135: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_relationship = df_relationship.append(df_group)\n",
      "C:\\Users\\ELAM2\\AppData\\Local\\Temp\\ipykernel_48232\\2988931172.py:135: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_relationship = df_relationship.append(df_group)\n",
      "C:\\Users\\ELAM2\\AppData\\Local\\Temp\\ipykernel_48232\\2988931172.py:135: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_relationship = df_relationship.append(df_group)\n",
      "C:\\Users\\ELAM2\\AppData\\Local\\Temp\\ipykernel_48232\\2988931172.py:135: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_relationship = df_relationship.append(df_group)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"style\"\n",
      "season\n",
      "po_season\n",
      "original_requested_production_end_date\n",
      "latest_confirmed_production_end_date\n",
      "payment_terms\n",
      "UPDATE\n",
      "dc_name\n",
      "UPDATE\n",
      "ship_to_name\n",
      "UPDATE\n",
      "season_cleaned\n",
      "UPDATE\n",
      "buy_month\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ELAM2\\AppData\\Local\\Temp\\ipykernel_48232\\2988931172.py:135: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_relationship = df_relationship.append(df_group)\n",
      "C:\\Users\\ELAM2\\AppData\\Local\\Temp\\ipykernel_48232\\2988931172.py:135: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_relationship = df_relationship.append(df_group)\n",
      "C:\\Users\\ELAM2\\AppData\\Local\\Temp\\ipykernel_48232\\2988931172.py:135: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_relationship = df_relationship.append(df_group)\n",
      "C:\\Users\\ELAM2\\AppData\\Local\\Temp\\ipykernel_48232\\2988931172.py:135: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_relationship = df_relationship.append(df_group)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UPDATE\n",
      "VF_Fiscal_Year_Original_crd\n",
      "VF_Fiscal_Year_Month_Original_crd\n",
      "UPDATE\n",
      "actual_ship_date\n",
      "UPDATE\n",
      "first_actual_ship_date\n",
      "CREATE\n",
      "UPDATE\n",
      "standard_duty_rate\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ELAM2\\AppData\\Local\\Temp\\ipykernel_48232\\2988931172.py:135: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_relationship = df_relationship.append(df_group)\n",
      "C:\\Users\\ELAM2\\AppData\\Local\\Temp\\ipykernel_48232\\2988931172.py:135: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_relationship = df_relationship.append(df_group)\n",
      "C:\\Users\\ELAM2\\AppData\\Local\\Temp\\ipykernel_48232\\2988931172.py:135: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_relationship = df_relationship.append(df_group)\n",
      "C:\\Users\\ELAM2\\AppData\\Local\\Temp\\ipykernel_48232\\2988931172.py:135: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_relationship = df_relationship.append(df_group)\n",
      "C:\\Users\\ELAM2\\AppData\\Local\\Temp\\ipykernel_48232\\2988931172.py:135: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_relationship = df_relationship.append(df_group)\n",
      "C:\\Users\\ELAM2\\AppData\\Local\\Temp\\ipykernel_48232\\2988931172.py:135: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_relationship = df_relationship.append(df_group)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UPDATE\n",
      "standard_duty_rate\n",
      "UPDATE\n",
      "standard_duty_rate\n",
      "UPDATE\n",
      "standard_duty_rate\n",
      "UPDATE\n",
      "preferential_duty_rate\n",
      "UPDATE\n",
      "cbm_pc_brand_cat\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ELAM2\\AppData\\Local\\Temp\\ipykernel_48232\\2988931172.py:135: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_relationship = df_relationship.append(df_group)\n",
      "C:\\Users\\ELAM2\\AppData\\Local\\Temp\\ipykernel_48232\\2988931172.py:135: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_relationship = df_relationship.append(df_group)\n",
      "C:\\Users\\ELAM2\\AppData\\Local\\Temp\\ipykernel_48232\\2988931172.py:135: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_relationship = df_relationship.append(df_group)\n",
      "C:\\Users\\ELAM2\\AppData\\Local\\Temp\\ipykernel_48232\\2988931172.py:135: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_relationship = df_relationship.append(df_group)\n",
      "C:\\Users\\ELAM2\\AppData\\Local\\Temp\\ipykernel_48232\\2988931172.py:135: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_relationship = df_relationship.append(df_group)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UPDATE\n",
      "freight_cost\n",
      "UNKNOWN\n",
      "can't define the sql type\n",
      "UPDATE\n",
      "applied_duty_rate\n",
      "calculated_duty_amt\n",
      "fully_landed_cost\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ELAM2\\AppData\\Local\\Temp\\ipykernel_48232\\2988931172.py:135: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_relationship = df_relationship.append(df_group)\n",
      "C:\\Users\\ELAM2\\AppData\\Local\\Temp\\ipykernel_48232\\2988931172.py:135: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_relationship = df_relationship.append(df_group)\n",
      "C:\\Users\\ELAM2\\AppData\\Local\\Temp\\ipykernel_48232\\2988931172.py:135: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_relationship = df_relationship.append(df_group)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UPDATE\n",
      "vendor_name\n",
      "vendor_group_name\n",
      "mdg_vendor_created_on\n",
      "mdg_vendor_purchasing_block\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ELAM2\\AppData\\Local\\Temp\\ipykernel_48232\\2988931172.py:135: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_relationship = df_relationship.append(df_group)\n",
      "C:\\Users\\ELAM2\\AppData\\Local\\Temp\\ipykernel_48232\\2988931172.py:135: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_relationship = df_relationship.append(df_group)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UPDATE\n",
      "factory_name\n",
      "mdg_factory_created_on\n",
      "mdg_factory_purchasing_block\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ELAM2\\AppData\\Local\\Temp\\ipykernel_48232\\2988931172.py:135: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_relationship = df_relationship.append(df_group)\n",
      "C:\\Users\\ELAM2\\AppData\\Local\\Temp\\ipykernel_48232\\2988931172.py:135: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_relationship = df_relationship.append(df_group)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INSERT\n",
      "snapshot_created_date\n",
      "snapshot_name\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ELAM2\\AppData\\Local\\Temp\\ipykernel_48232\\2988931172.py:135: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_relationship = df_relationship.append(df_group)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "country_of_origin\n",
      "po_cut\n",
      "style\n",
      "color\n",
      "style_description\n",
      "goods_description\n",
      "po_issue_date\n",
      "original_crd_at_origin\n",
      "revised_crd_at_origin\n",
      "actual_crd_at_origin\n",
      "local_currency\n",
      "unit_price\n",
      "season\n",
      "sourcing_office\n",
      "source_system\n",
      "dc_code\n",
      "po_type\n",
      "purchasing_group\n",
      "sbu\n",
      "sub_sbu\n",
      "product_line\n",
      "purchasing_company\n",
      "vendor_ffc\n",
      "vendor_group_name\n",
      "factory_ffc\n",
      "delay_reason\n",
      "shipment_terms\n",
      "po_location\n",
      "destination_country\n",
      "vendor_name\n",
      "factory_name\n",
      "report_order_qty_lum\n",
      "order_amount_local_currency\n",
      "shipped_qty_lum\n",
      "shipped_amt_local_currency\n",
      "booked_qty_lum\n",
      "booked_amt_local_currency\n",
      "effective_crd\n",
      "effective_qty\n",
      "order_type_calculated\n",
      "qty_per_pack\n",
      "issample\n",
      "iscustomorder\n",
      "managing_office\n",
      "brand\n",
      "major_product_category_name\n",
      "business_unit\n",
      "brand2\n",
      "market\n",
      "order_amount_usd\n",
      "shipped_amt_usd\n",
      "booked_amt_usd\n",
      "effective_amt_usd\n",
      "exchange_rate\n",
      "product_supply_group\n",
      "CURRENT_DATE\n",
      "src_sys\n",
      "table_names\n",
      "effective_crd_year\n",
      "effective_crd_month\n",
      "misc3\n",
      "misc26\n",
      "misc33\n",
      "purchasing_company_code\n",
      "days_late\n",
      "exch_rate_date\n",
      "od_misc_flag\n",
      "tbr_defect_flag\n",
      "po_creation_date\n",
      "balance_qty\n",
      "shipment_id\n",
      "fr_release\n",
      "factory_designation\n",
      "hts_code\n",
      "dc_name\n",
      "erp_factory_code\n",
      "erp_vendor_code\n",
      "revised_in_dc_date\n",
      "ship_mode\n",
      "po_acknowledgement_date\n",
      "po_complete_status\n",
      "po_season\n",
      "shipment_id_closing_date\n",
      "actual_ship_date\n",
      "first_actual_crd\n",
      "first_shipment_id\n",
      "first_actual_ship_date\n",
      "shipment_status\n",
      "greenlight_date\n",
      "hts_product_category\n",
      "hts_product_type\n",
      "crc_code\n",
      "crc_description\n",
      "costing_season\n",
      "master_po\n",
      "orders_to_be_produced_qty\n",
      "orders_to_be_produced_amt_usd\n",
      "actual_produced_qty\n",
      "actual_produced_amt_usd\n",
      "freight_paid_by\n",
      "exit_cnty_port\n",
      "ship_to_name\n",
      "original_requested_production_end_date\n",
      "latest_confirmed_production_end_date\n",
      "vf_est_dc_arrival_date\n",
      "brand_requested_in_dc_date\n",
      "buy_month\n",
      "unit_price_average_in_usd\n",
      "container_number\n",
      "shipment_closed_by\n",
      "requested_delivery_date\n",
      "po_closure_eligibility\n",
      "discharge_at_port_of_destination\n",
      "crc_owner\n",
      "asn_released_to_3pl\n",
      "revised_production_end_date\n",
      "original_brands_requested_crd\n",
      "certified_pocut_flag\n",
      "fob_price\n",
      "fob_duties_rate\n",
      "material_in_house_planned_date\n",
      "material_in_house_revised_plan_date\n",
      "material_in_house_actual_date\n",
      "cutting_planned_date\n",
      "cutting_revised_planned_date\n",
      "cutting_actual_date\n",
      "sewing_stitching_planned_date\n",
      "sewing_stitching_revised_plan_date\n",
      "sewing_stitching_actual_date\n",
      "finishing_assembly_planned_date\n",
      "finishing_assembly_revised_plan_date\n",
      "finishing_assembly_actual_date\n",
      "production_priority_flag\n",
      "order_collaboration_line_status_latest\n",
      "plan_to_ship_qty_lum\n",
      "packing_list_qty\n",
      "split_from_po\n",
      "material_in_house_qty\n",
      "cutting_qty\n",
      "sewing_stitching_qty\n",
      "finishing_assembly_qty\n",
      "payment_Terms\n",
      "Capacity_Group\n",
      "Marketing_Program\n",
      "certprintdate\n",
      "SpeedProgram\n",
      "ProductDevelopmentType\n",
      "GlobalBrandArchitecture\n",
      "VF_Fiscal_Year_Original_crd\n",
      "VF_Fiscal_Year_Month_Original_crd\n",
      "season_cleaned\n",
      "fob_price_usd\n",
      "pl_uom\n",
      "asn_uom\n",
      "preferential_duty_rate\n",
      "standard_duty_rate\n",
      "freight_cost\n",
      "applied_duty_rate\n",
      "calculated_duty_amt\n",
      "fully_landed_cost\n",
      "cbm_pc_brand_cat\n",
      "standard_duty_specific_rate\n",
      "mdg_vendor_created_on\n",
      "mdg_vendor_purchasing_block\n",
      "mdg_factory_created_on\n",
      "mdg_factory_purchasing_block\n",
      "first_confirmed_crc\n",
      "UPDATE\n",
      "week_tag\n",
      "INSERT\n",
      "snapshot_created_date\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ELAM2\\AppData\\Local\\Temp\\ipykernel_48232\\2988931172.py:135: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_relationship = df_relationship.append(df_group)\n",
      "C:\\Users\\ELAM2\\AppData\\Local\\Temp\\ipykernel_48232\\2988931172.py:135: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_relationship = df_relationship.append(df_group)\n",
      "C:\\Users\\ELAM2\\AppData\\Local\\Temp\\ipykernel_48232\\2988931172.py:135: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_relationship = df_relationship.append(df_group)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "snapshot_name\n",
      "country_of_origin\n",
      "po_cut\n",
      "\"style\"\n",
      "color\n",
      "style_description\n",
      "goods_description\n",
      "po_issue_date\n",
      "original_crd_at_origin\n",
      "revised_crd_at_origin\n",
      "actual_crd_at_origin\n",
      "local_currency\n",
      "unit_price\n",
      "season\n",
      "sourcing_office\n",
      "source_system\n",
      "dc_code\n",
      "po_type\n",
      "purchasing_group\n",
      "sbu\n",
      "sub_sbu\n",
      "product_line\n",
      "purchasing_company\n",
      "vendor_ffc\n",
      "vendor_group_name\n",
      "factory_ffc\n",
      "delay_reason\n",
      "shipment_terms\n",
      "po_location\n",
      "destination_country\n",
      "vendor_name\n",
      "factory_name\n",
      "report_order_qty_lum\n",
      "order_amount_local_currency\n",
      "shipped_qty_lum\n",
      "shipped_amt_local_currency\n",
      "booked_qty_lum\n",
      "booked_amt_local_currency\n",
      "effective_crd\n",
      "effective_qty\n",
      "order_type_calculated\n",
      "qty_per_pack\n",
      "issample\n",
      "iscustomorder\n",
      "managing_office\n",
      "brand\n",
      "major_product_category_name\n",
      "business_unit\n",
      "brand2\n",
      "market\n",
      "order_amount_usd\n",
      "shipped_amt_usd\n",
      "booked_amt_usd\n",
      "effective_amt_usd\n",
      "exchange_rate\n",
      "product_supply_group\n",
      "CURRENT_DATE\n",
      "src_sys\n",
      "table_names\n",
      "effective_crd_year\n",
      "effective_crd_month\n",
      "misc3\n",
      "misc26\n",
      "misc33\n",
      "purchasing_company_code\n",
      "days_late\n",
      "exch_rate_date\n",
      "od_misc_flag\n",
      "tbr_defect_flag\n",
      "po_creation_date\n",
      "balance_qty\n",
      "shipment_id\n",
      "fr_release\n",
      "factory_designation\n",
      "hts_code\n",
      "dc_name\n",
      "erp_factory_code\n",
      "erp_vendor_code\n",
      "revised_in_dc_date\n",
      "ship_mode\n",
      "po_acknowledgement_date\n",
      "po_complete_status\n",
      "po_season\n",
      "shipment_id_closing_date\n",
      "actual_ship_date\n",
      "first_actual_crd\n",
      "first_shipment_id\n",
      "first_actual_ship_date\n",
      "shipment_status\n",
      "greenlight_date\n",
      "hts_product_category\n",
      "hts_product_type\n",
      "crc_code\n",
      "crc_description\n",
      "costing_season\n",
      "master_po\n",
      "orders_to_be_produced_qty\n",
      "orders_to_be_produced_amt_usd\n",
      "actual_produced_qty\n",
      "actual_produced_amt_usd\n",
      "freight_paid_by\n",
      "exit_cnty_port\n",
      "ship_to_name\n",
      "original_requested_production_end_date\n",
      "latest_confirmed_production_end_date\n",
      "vf_est_dc_arrival_date\n",
      "brand_requested_in_dc_date\n",
      "buy_month\n",
      "unit_price_average_in_usd\n",
      "container_number\n",
      "shipment_closed_by\n",
      "requested_delivery_date\n",
      "po_closure_eligibility\n",
      "discharge_at_port_of_destination\n",
      "crc_owner\n",
      "asn_released_to_3pl\n",
      "revised_production_end_date\n",
      "original_brands_requested_crd\n",
      "certified_pocut_flag\n",
      "fob_duties_rate\n",
      "fob_price\n",
      "material_in_house_planned_date\n",
      "material_in_house_revised_plan_date\n",
      "material_in_house_actual_date\n",
      "cutting_planned_date\n",
      "cutting_revised_planned_date\n",
      "cutting_actual_date\n",
      "sewing_stitching_planned_date\n",
      "sewing_stitching_revised_plan_date\n",
      "sewing_stitching_actual_date\n",
      "finishing_assembly_planned_date\n",
      "finishing_assembly_revised_plan_date\n",
      "finishing_assembly_actual_date\n",
      "production_priority_flag\n",
      "order_collaboration_line_status_latest\n",
      "plan_to_ship_qty_lum\n",
      "packing_list_qty\n",
      "split_from_po\n",
      "shipment_term\n",
      "payment_terms\n",
      "capacity_group\n",
      "marketing_program\n",
      "week_tag\n",
      "certprintdate\n",
      "material_in_house_qty\n",
      "cutting_qty\n",
      "sewing_stitching_qty\n",
      "finishing_assembly_qty\n",
      "speedprogram\n",
      "productdevelopmenttype\n",
      "globalbrandarchitecture\n",
      "vf_fiscal_year_month_original_crd\n",
      "vf_fiscal_year_original_crd\n",
      "season_cleaned\n",
      "fob_price_usd\n",
      "pl_uom\n",
      "asn_uom\n",
      "preferential_duty_rate\n",
      "standard_duty_rate\n",
      "freight_cost\n",
      "applied_duty_rate\n",
      "calculated_duty_amt\n",
      "fully_landed_cost\n",
      "cbm_pc_brand_cat\n",
      "standard_duty_specific_rate\n",
      "mdg_vendor_created_on\n",
      "mdg_vendor_purchasing_block\n",
      "mdg_factory_created_on\n",
      "mdg_factory_purchasing_block\n",
      "first_confirmed_crc\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "for file in os.listdir(\"stored procedure\"):\n",
    "    if file.endswith(\".txt\"):\n",
    "        print(os.path.join(\"stored procedure\", file))\n",
    "\n",
    "        with open(os.path.join(\"stored procedure\", file), 'r', encoding=\"utf8\") as f:\n",
    "            #remove illegal words\n",
    "            text = f.read().replace('~', '!=')\n",
    "            text = text.replace('#', '')\n",
    "            lines = text.split(';')\n",
    "\n",
    "            sql_2_b_processed = []\n",
    "            fail_2_processed = []\n",
    "            stored_procedure_called = []\n",
    "\n",
    "            for sql in lines:\n",
    "\n",
    "                if ('insert' in sql.lower() or 'update' in sql.lower()): #grab all building block to build the database\n",
    "\n",
    "                    sql_2_b_processed.append(sql)\n",
    "\n",
    "                elif ('call' in sql.lower()): #to grap all procedure called within procedure\n",
    "\n",
    "                    stored_procedure_called.append(sql)\n",
    "\n",
    "                else: \n",
    "\n",
    "                    fail_2_processed.append(sql)\n",
    "\n",
    "            print(f\"filename is {file.replace('.txt', '')}.\")\n",
    "            print(f\"there are: {len(sql_2_b_processed)} lines.\")\n",
    "            \n",
    "            get_sp_column_lineage_relationship(sql_2_b_processed, file.replace('.txt', ''))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
